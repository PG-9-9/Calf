{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3058362/323789853.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-02-21 14:39:28.627495: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-21 14:39:30.155015: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-21 14:39:30.155192: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-21 14:39:30.381866: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-21 14:39:30.808724: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-21 14:39:47.955558: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, precision_recall_curve\n",
    ")\n",
    "\n",
    "from tensorflow.keras import layers, models, Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Input, BatchNormalization, LSTM, RepeatVector,\n",
    "    TimeDistributed\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder last ran on: 2024-02-21 11:31:30\n"
     ]
    }
   ],
   "source": [
    "current_datetime=datetime.datetime.now()\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "print(f\"AutoEncoder last ran on: {current_datetime.strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding Window\n",
    "\n",
    "def sliding_window(audio, window_size, step_size, sample_rate):\n",
    "    num_samples_per_window = int(window_size * sample_rate)\n",
    "    step_samples = int(step_size * sample_rate)\n",
    "    windows = []\n",
    "    for start in range(0, len(audio) - num_samples_per_window + 1, step_samples):\n",
    "        window = audio[start:start + num_samples_per_window]\n",
    "        windows.append(window)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction:\n",
    "\n",
    "# MFCCs (Power Spectrum)\n",
    "def extract_mfccs(audio, sample_rate, n_mfcc=13):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "    mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_processed\n",
    "\n",
    "# Spectral Features (spectral centroid, spectral roll-off, and spectral contrast):\n",
    "def extract_spectral_features(audio, sample_rate):\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sample_rate)[0]\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sample_rate)[0]\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sample_rate)[0]\n",
    "    return np.mean(spectral_centroids), np.mean(spectral_rolloff), np.mean(spectral_contrast)\n",
    "\n",
    "# Temporal Features ( zero-crossing rate and autocorrelation):\n",
    "def extract_temporal_features(audio):\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)[0]\n",
    "    autocorrelation = librosa.autocorrelate(audio)\n",
    "    return np.mean(zero_crossing_rate), np.mean(autocorrelation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio files and apply sliding windows\n",
    "\n",
    "def load_and_window_audio_files(path, label, window_size, step_size, sample_rate):\n",
    "    audio_windows = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(path, filename)\n",
    "            audio, _ = librosa.load(file_path, sr=sample_rate)\n",
    "            windows = sliding_window(audio, window_size, step_size, sample_rate)\n",
    "            audio_windows.extend(windows)\n",
    "            labels.extend([label] * len(windows))\n",
    "    return audio_windows, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction for each window\n",
    "\n",
    "def extract_features(audio_windows, sample_rate):\n",
    "    features = []\n",
    "    for window in audio_windows:\n",
    "        mfccs = extract_mfccs(window, sample_rate)\n",
    "        spectral_features = extract_spectral_features(window, sample_rate)\n",
    "        temporal_features = extract_temporal_features(window)\n",
    "        all_features = np.concatenate([mfccs, spectral_features, temporal_features])\n",
    "        features.append(all_features)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_calf_path=\"Calf_Detection/Audio/Audio_Work_AE/normal_calf_subset\"\n",
    "abnormal_calf_path = \"Calf_Detection/Audio/Audio_Work_AE/abnormal_calf_subset\"\n",
    "\n",
    "window_size = 10  # in seconds\n",
    "step_size = 5  # in seconds\n",
    "sample_rate = 44100  \n",
    "\n",
    "# Load and window the data\n",
    "normal_audio_windows, normal_labels = load_and_window_audio_files(normal_calf_path, label=0, window_size=window_size, step_size=step_size, sample_rate=sample_rate)\n",
    "abnormal_audio_windows, abnormal_labels = load_and_window_audio_files(abnormal_calf_path, label=1, window_size=window_size, step_size=step_size, sample_rate=sample_rate)\n",
    "\n",
    "# Extract features for windows\n",
    "normal_features = extract_features(normal_audio_windows, sample_rate)\n",
    "abnormal_features = extract_features(abnormal_audio_windows, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 15:35:12,597 - INFO - Starting data processing\n",
      "2024-01-02 15:35:12,601 - INFO - Completed scaling\n",
      "2024-01-02 15:35:12,602 - INFO - Data reshaped: (514, 1, 18)\n",
      "2024-01-02 15:35:12,603 - INFO - Model training with data shape: (514, 1, 18)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# Further simplified LSTM autoencoder\n",
    "def enhanced_autoencoder_with_lstm(timesteps, n_features):\n",
    "    input_layer = Input(shape=(timesteps, n_features))\n",
    "\n",
    "    # Very simple Encoder with LSTM\n",
    "    encoder = LSTM(16, activation='relu', return_sequences=False)(input_layer)\n",
    "    encoder = BatchNormalization()(encoder)\n",
    "    encoder = Dropout(0.1)(encoder)\n",
    "\n",
    "    # Repeat Vector\n",
    "    repeat_vector = RepeatVector(timesteps)(encoder)\n",
    "\n",
    "    # Very simple Decoder with LSTM\n",
    "    decoder = LSTM(16, activation='relu', return_sequences=True)(repeat_vector)\n",
    "    decoder = BatchNormalization()(decoder)\n",
    "    decoder = Dropout(0.1)(decoder)\n",
    "    output_layer = TimeDistributed(Dense(n_features))(decoder)\n",
    "\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return autoencoder\n",
    "\n",
    "def process_data(features):\n",
    "    logging.info(\"Starting data processing\")\n",
    "    X_train, X_val = train_test_split(features, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    logging.info(\"Completed scaling\")\n",
    "\n",
    "    # Reshape data for LSTM\n",
    "    timesteps = 1  # Assuming each window is treated as a separate sequence\n",
    "    n_features = X_train_scaled.shape[1]\n",
    "    X_train_reshaped = X_train_scaled.reshape((-1, timesteps, n_features))\n",
    "    X_val_reshaped = X_val_scaled.reshape((-1, timesteps, n_features))\n",
    "    logging.info(f\"Data reshaped: {X_train_reshaped.shape}\")\n",
    "\n",
    "    return X_train_reshaped, X_val_reshaped\n",
    "\n",
    "def train_model(X_train, X_val):\n",
    "    logging.info(f\"Model training with data shape: {X_train.shape}\")\n",
    "    try:\n",
    "        autoencoder = enhanced_autoencoder_with_lstm(X_train.shape[1], X_train.shape[2])\n",
    "        autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, validation_data=(X_val, X_val),\n",
    "                        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)], verbose=1)\n",
    "        logging.info(\"Model training completed\")\n",
    "    except Exception as e:\n",
    "        logging.error(\"An error occurred during model training\", exc_info=True)\n",
    "\n",
    "# Main script\n",
    "try:\n",
    "    normal_features = np.array(normal_features)\n",
    "    X_train_reshaped, X_val_reshaped = process_data(normal_features)\n",
    "    train_model(X_train_reshaped, X_val_reshaped)\n",
    "except Exception as e:\n",
    "    logging.error(\"An error occurred in the main script\", exc_info=True)\n",
    "\n",
    "# Test with synthetic data\n",
    "try:\n",
    "    synthetic_data = np.random.rand(30, 1, 18)\n",
    "    train_model(synthetic_data, synthetic_data)\n",
    "except Exception as e:\n",
    "    logging.error(\"Error with synthetic data\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_en",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
