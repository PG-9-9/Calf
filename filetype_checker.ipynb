{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique filetypes found:\n",
      ".txt\n",
      ".v2\n",
      ".fb\n",
      ".yaml\n",
      ".py\n",
      ".gif\n",
      ".pyc\n",
      ".index\n",
      ".config\n",
      ".keras\n",
      ".png\n",
      ".cc\n",
      ".pack\n",
      ".npy\n",
      ".ini\n",
      ".gz\n",
      ".record\n",
      ".tpl\n",
      ".jpeg\n",
      ".pbtxt\n",
      ".md\n",
      ".json\n",
      ".gin\n",
      ".screenrc\n",
      ".ipynb\n",
      ".code-workspace\n",
      ".pb\n",
      ".h\n",
      ".tfrecord\n",
      ".sample\n",
      ".csv\n",
      ".asciipb\n",
      ".mat\n",
      ".mp3\n",
      ".html\n",
      ".meta\n",
      ".data-00000-of-00001\n",
      ".sh\n",
      ".rcfile\n",
      ".jpg\n",
      ".idx\n",
      ".xml\n",
      ".bzl\n",
      ".proto\n",
      ".yml\n",
      ".BUILD\n",
      ".wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def print_unique_filetypes(directory):\n",
    "    unique_filetypes = set()\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            _, extension = os.path.splitext(file)\n",
    "            if extension:  \n",
    "                unique_filetypes.add(extension)\n",
    "\n",
    "    print(\"Unique filetypes found:\")\n",
    "    for filetype in unique_filetypes:\n",
    "        print(filetype)\n",
    "\n",
    "directory_path = 'Calf_Detection' \n",
    "print_unique_filetypes(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calf_Detection/.git/objects/pack/pack-c8d4d74ca02a8e460c0a0fb1ef04a0d70412e6f5.pack: 852415252 bytes\n",
      "Calf_Detection/models/.git/objects/pack/pack-d341b8258a6c521dec2fee44bf5e57f43da8b633.pack: 628346747 bytes\n",
      "Calf_Detection/models/.git/objects/pack/pack-80b6dab021cad132e6736cd77a8bd2f0b29e132b.pack: 627945480 bytes\n",
      "Calf_Detection/new_app/New_Models/training/epochs_10/efficientdet_d7_coco17_tpu-32/ckpt-4.data-00000-of-00001: 443166648 bytes\n",
      "Calf_Detection/new_app/New_Models/training/epochs_10/efficientdet_d7_coco17_tpu-32/ckpt-2.data-00000-of-00001: 443166648 bytes\n",
      "Calf_Detection/new_app/New_Models/training/epochs_10/efficientdet_d7_coco17_tpu-32/ckpt-3.data-00000-of-00001: 443166648 bytes\n",
      "Calf_Detection/new_app/New_Models/training/epochs_10/efficientdet_d6_coco17_tpu-32/ckpt-4.data-00000-of-00001: 443166648 bytes\n",
      "Calf_Detection/new_app/New_Models/training/epochs_10/efficientdet_d6_coco17_tpu-32/ckpt-2.data-00000-of-00001: 443166648 bytes\n",
      "Calf_Detection/new_app/New_Models/training/epochs_10/efficientdet_d6_coco17_tpu-32/ckpt-3.data-00000-of-00001: 443166648 bytes\n",
      "Calf_Detection/new_app/New_Models/efficientdet_d7_coco17_tpu-32.tar.gz: 394474998 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def find_largest_files(directory):\n",
    "    # This list will store tuples of (file size, file name)\n",
    "    files_with_size = []\n",
    "\n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            filepath = os.path.join(root, name)\n",
    "            try:\n",
    "                # Get the size of the file\n",
    "                size = os.path.getsize(filepath)\n",
    "                # Add the tuple (size, filepath) to the list\n",
    "                files_with_size.append((size, filepath))\n",
    "            except OSError as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    # Sort the list by file size in descending order\n",
    "    files_with_size.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Print the top 10 largest files\n",
    "    for size, name in files_with_size[:10]:\n",
    "        print(f\"{name}: {size} bytes\")\n",
    "\n",
    "\n",
    "find_largest_files('Calf_Detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
